{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"./\"\n",
    "\n",
    "# Input\n",
    "SAMPLE_DATASET_PATH = PREFIX + \"sample_submission.csv\"\n",
    "TRAIN_DATASET_PATH = PREFIX + \"train.csv\"\n",
    "TEST_DATASET_PATH = PREFIX + \"test.csv\"\n",
    "\n",
    "# Output\n",
    "RESULT = \"TEMER_result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "mean_exam_points       10000 non-null float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_DATASET_PATH, sep=\",\")\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 781.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_df = train_data.drop(['Id', 'mean_exam_points'], axis=1)\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00e+01, 0.00e+00, 1.40e+03, ..., 0.00e+00, 1.00e+00, 0.00e+00],\n",
       "       [4.80e+01, 4.00e+00, 2.85e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.90e+01, 0.00e+00, 1.20e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       ...,\n",
       "       [3.40e+01, 1.00e+00, 1.25e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.30e+01, 3.00e+00, 1.10e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [3.50e+01, 0.00e+00, 1.45e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_df.values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      "mean_exam_points    10000 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "y_df = train_data[['mean_exam_points']]\n",
    "y_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63., 86., 53., ..., 58., 51., 59.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_df.values.flatten()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 859.5 KB\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(TEST_DATASET_PATH, sep=\",\")\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 781.4 KB\n"
     ]
    }
   ],
   "source": [
    "x_df = test_data.drop(['Id'], axis=1)\n",
    "x_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.60e+01, 3.00e+00, 1.05e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.30e+01, 3.00e+00, 1.85e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [5.20e+01, 1.00e+00, 1.55e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       ...,\n",
       "       [3.30e+01, 5.00e+00, 1.10e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.80e+01, 0.00e+00, 1.75e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [4.90e+01, 5.00e+00, 2.00e+03, ..., 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = x_df.values\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "    \"\"\"предсказание с помощью градиентного бустинга\"\"\"\n",
    "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании \n",
    "    # прибавляются с шагом eta\n",
    "    return np.array([sum([\n",
    "        eta * coef * alg.predict([x])[0] for alg, coef in zip(trees_list, coef_list)]) \n",
    "                     for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_real, prediction):\n",
    "    \"\"\"среднеквадратичная ошибка\"\"\"\n",
    "    return (sum((y_real - prediction) ** 2)) / len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(y, z):\n",
    "    \"\"\"смещение для L2-loss\"\"\"\n",
    "    return - 2 * (z - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit(DecisionTreeClass, n_trees, max_depth, eta, coefs, error_func, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"обучение градиентного бустинга\"\"\"\n",
    "    \n",
    "    # eta - скорость обучения\n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        tree = DecisionTreeClass(max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "            \n",
    "            if (X_train is not None) and (y_train is not None):\n",
    "                train_errors.append(error_func(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            if (X_test is not None) and (y_test is not None):\n",
    "                test_errors.append(error_func(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            z_train = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы, начиная со второго, обучаем на сдвиг\n",
    "            tree.fit(X_train, bias(y_train, z_train))\n",
    "            \n",
    "            if (X_train is not None) and (y_train is not None):\n",
    "                train_errors.append(error_func(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            if (X_test is not None) and (y_test is not None):\n",
    "                test_errors.append(error_func(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels):\n",
    "    \"\"\"критерий Джини\"\"\"\n",
    "    #  подсчёт количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчёт критерия\n",
    "    impurity = 1 # коэффициент неопределённости Джини\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"узел дерева\"\"\"\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведётся сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"лист дерева\"\"\"\n",
    "    \n",
    "    def __init__(self, data, labels, regression):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.regression = regression\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        if self.regression:\n",
    "            prediction = np.mean(self.labels)  # среднее значение по выборке\n",
    "        else:\n",
    "            # подсчёт количества объектов разных классов\n",
    "            classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "            for label in self.labels:\n",
    "                if label not in classes:\n",
    "                    classes[label] = 0 \n",
    "                classes[label] += 1\n",
    "            # найдём класс, количество объектов которого будет максимальным в этом листе и вернём его\n",
    "            prediction = max(classes, key=classes.get)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self, random_state=None, min_leaf=1, max_depth=10**9, max_leaf_nodes=10**9, regression=True):\n",
    "        \"\"\"\n",
    "        конструктор дерева\n",
    "\n",
    "        :param min_leaf: минимальное количество объектов в листе\n",
    "        :param max_depth: максимальная глубина дерева\n",
    "        :param max_leaf_nodes: максимальное количество листьев\n",
    "        :param inf_crit_func: критерий информативности\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        self.min_leaf = min_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.regression = regression\n",
    "        self.inf_crit_func = np.var if regression else gini  # критерий информативности\n",
    "    \n",
    "    def quality(self, left_labels, right_labels, current_inf_crit):\n",
    "        \"\"\"расчёт качества\"\"\"\n",
    "        # доля выбоки, ушедшая в левое поддерево\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])  \n",
    "        return current_inf_crit - p * self.inf_crit_func(left_labels) - (1 - p) * self.inf_crit_func(right_labels)\n",
    "    \n",
    "    def split(self, data, labels, index, t):\n",
    "        \"\"\"разбиение датасета в узле\"\"\"\n",
    "\n",
    "        left = np.where(data[:, index] <= t)\n",
    "        right = np.where(data[:, index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    def find_best_split(self, data, labels):\n",
    "        \"\"\"нахождение наилучшего разбиения\"\"\"\n",
    "\n",
    "        current_inf_crit = self.inf_crit_func(labels)\n",
    "\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        for index in range(n_features):\n",
    "            # будем проверять только уникальные значения признака, исключая повторения\n",
    "            t_values = np.unique([row[index] for row in data])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "                # пропускаем разбиения, в которых в узле остаётся менее min_leaf объектов\n",
    "                if len(true_data) < self.min_leaf or len(false_data) < self.min_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_quality = self.quality(true_labels, false_labels, current_inf_crit)\n",
    "\n",
    "                # выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "        return best_quality, best_t, best_index\n",
    "    \n",
    "    def build_tree(self, data, labels, _leaves=0, _branches=0, _depth=0):\n",
    "        \"\"\"\n",
    "        построение дерева с помощью рекурсивной функции\n",
    "\n",
    "        :param data: данные\n",
    "        :param labels: метки\n",
    "        :return: узел дерева, кол-во листьев, кол-во ветвей\n",
    "        \"\"\"\n",
    "\n",
    "        quality, t, index = self.find_best_split(data, labels)\n",
    "\n",
    "        # Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "        if (quality == 0) or ((self.max_leaf_nodes - _leaves - _branches) < 2) or (_depth >= self.max_depth):\n",
    "            _leaves += 1\n",
    "            return Leaf(data, labels, regression=self.regression), _leaves, _branches\n",
    "\n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        # Рекурсивно строим два поддерева\n",
    "        _branches += 1\n",
    "        true_branch, _leaves, _branches = self.build_tree(true_data, true_labels, _leaves, _branches, _depth+1)\n",
    "        _branches -= 1\n",
    "        false_branch, _leaves, _branches = self.build_tree(false_data, false_labels, _leaves, _branches, _depth+1)\n",
    "\n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        self.root = Node(index, t, true_branch, false_branch)\n",
    "        return self.root, _leaves, _branches\n",
    "    \n",
    "    def classify_object(self, obj, node):\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.classify_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.classify_object(obj, node.false_branch)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        reg_tree, *_ = self.build_tree(X, y)\n",
    "        return reg_tree\n",
    "    \n",
    "    def predict(self, X):\n",
    "        classes = []\n",
    "        for obj in X:\n",
    "            prediction = self.classify_object(obj, self.root)\n",
    "            classes.append(prediction)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка алгоритма из\t50 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.783\n",
      "Ошибка алгоритма из\t50 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.770\n",
      "\n",
      "Ошибка алгоритма из\t50 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.815\n",
      "Ошибка алгоритма из\t50 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.778\n",
      "\n",
      "Ошибка алгоритма из\t60 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.786\n",
      "Ошибка алгоритма из\t60 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.772\n",
      "\n",
      "Ошибка алгоритма из\t60 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.818\n",
      "Ошибка алгоритма из\t60 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.778\n",
      "\n",
      "Ошибка алгоритма из\t70 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.788\n",
      "Ошибка алгоритма из\t70 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.773\n",
      "\n",
      "Ошибка алгоритма из\t70 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.822\n",
      "Ошибка алгоритма из\t70 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.777\n",
      "\n",
      "Ошибка алгоритма из\t80 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.789\n",
      "Ошибка алгоритма из\t80 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.773\n",
      "\n",
      "Ошибка алгоритма из\t80 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.824\n",
      "Ошибка алгоритма из\t80 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.777\n",
      "\n",
      "Ошибка алгоритма из\t90 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.790\n",
      "Ошибка алгоритма из\t90 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.773\n",
      "\n",
      "Ошибка алгоритма из\t90 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.827\n",
      "Ошибка алгоритма из\t90 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.775\n",
      "\n",
      "Ошибка алгоритма из\t100 деревьев\tглубиной 3\tс шагом 0.1\tна тренировочной выборке:\t0.792\n",
      "Ошибка алгоритма из\t100 деревьев\tглубиной 3\tс шагом 0.1\tна   тестовой    выборке:\t0.773\n",
      "\n",
      "Ошибка алгоритма из\t100 деревьев\tглубиной 5\tс шагом 0.1\tна тренировочной выборке:\t0.830\n",
      "Ошибка алгоритма из\t100 деревьев\tглубиной 5\tс шагом 0.1\tна   тестовой    выборке:\t0.775\n",
      "\n",
      "Лучшие параметры: Ошибка алгоритма из 60 деревьев глубиной 5 с шагом 0.1 на тестовой выборке: 0.7783740946241727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "err_min = 0\n",
    "for n_trees in range(50, 100+1, 10):\n",
    "    for max_depth in [3, 5]:\n",
    "        for eta in [0.1]:\n",
    "            coefs = [1] * n_trees  # для простоты примем коэффициенты равными 1\n",
    "            trees, train_errors, test_errors = \\\n",
    "            gb_fit(MyDecisionTree, n_trees, max_depth, eta, coefs, mean_squared_error,\n",
    "                   XX_train, XX_test, yy_train, yy_test)\n",
    "            \n",
    "            train_prediction = gb_predict(XX_train, trees, coefs, eta)\n",
    "            err = r2_score(yy_train, train_prediction)\n",
    "            print(f'Ошибка алгоритма из\\t{n_trees} деревьев\\tглубиной {max_depth}'\n",
    "                  f'\\tс шагом {eta}\\tна тренировочной выборке:\\t{err:.3f}')\n",
    "            \n",
    "            test_prediction = gb_predict(XX_test, trees, coefs, eta)\n",
    "            err = r2_score(yy_test, test_prediction)\n",
    "            print(f'Ошибка алгоритма из\\t{n_trees} деревьев\\tглубиной {max_depth}'\n",
    "                  f'\\tс шагом {eta}\\tна   тестовой    выборке:\\t{err:.3f}')\n",
    "            \n",
    "            if err_min < err:\n",
    "                n_trees_best = len(trees)\n",
    "                max_depth_best = max_depth\n",
    "                eta_best = eta\n",
    "                err_min = err\n",
    "            print()\n",
    "print(f'Лучшие параметры: Ошибка алгоритма из {n_trees_best} деревьев глубиной {max_depth_best} с шагом {eta_best} на тестовой выборке: {err_min}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 60\n",
    "coefs = [1] * n_trees  # для простоты примем коэффициенты равными 1\n",
    "max_depth = 5\n",
    "eta = 0.1\n",
    "\n",
    "trees, _, _ = gb_fit(MyDecisionTree, n_trees, max_depth, eta, coefs, mean_squared_error,\n",
    "                     X_train, None, y_train, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.98410924, 63.10775093, 48.05332314, ..., 54.58803529,\n",
       "       64.77470306, 69.0279692 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = gb_predict(X_test, trees, coefs, eta)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>53.984109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>63.107751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>48.053323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>91.179312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>88.778316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19995</td>\n",
       "      <td>42.207201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19996</td>\n",
       "      <td>78.732077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19997</td>\n",
       "      <td>54.588035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19998</td>\n",
       "      <td>64.774703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19999</td>\n",
       "      <td>69.027969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  mean_exam_points\n",
       "0     10000         53.984109\n",
       "1     10001         63.107751\n",
       "2     10002         48.053323\n",
       "3     10003         91.179312\n",
       "4     10004         88.778316\n",
       "...     ...               ...\n",
       "9995  19995         42.207201\n",
       "9996  19996         78.732077\n",
       "9997  19997         54.588035\n",
       "9998  19998         64.774703\n",
       "9999  19999         69.027969\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = test_data[['Id']].copy()\n",
    "res = pd.concat([res, pd.DataFrame(prediction, columns=['mean_exam_points'])], axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(RESULT, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
